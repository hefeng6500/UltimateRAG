"""
å…ƒæ•°æ®æå–æ¨¡å—

ä»Žæ–‡æ¡£ä¸­æå–ç»“æž„åŒ–å…ƒæ•°æ®ï¼Œç”¨äºŽåŽç»­çš„è¿‡æ»¤æ£€ç´¢ã€‚
æ”¯æŒæå–æ ‡é¢˜ã€æ—¥æœŸã€ä½œè€…ç­‰ä¿¡æ¯ã€‚
"""

import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path
from loguru import logger

from langchain_core.documents import Document


class MetadataExtractor:
    """
    å…ƒæ•°æ®æå–å™¨
    
    ä»Žæ–‡æ¡£å†…å®¹å’Œæ–‡ä»¶è·¯å¾„ä¸­æå–æœ‰ä»·å€¼çš„å…ƒæ•°æ®ã€‚
    """
    
    # å¸¸è§çš„æ—¥æœŸæ ¼å¼
    DATE_PATTERNS = [
        r"\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}[æ—¥]?",  # 2024-01-01, 2024å¹´1æœˆ1æ—¥
        r"\d{1,2}[-/]\d{1,2}[-/]\d{4}",           # 01-01-2024
        r"\d{4}\d{2}\d{2}",                       # 20240101
    ]
    
    # Markdown æ ‡é¢˜æ¨¡å¼
    HEADER_PATTERNS = [
        r"^#\s+(.+)$",      # # Title
        r"^##\s+(.+)$",     # ## Subtitle
        r"^###\s+(.+)$",    # ### Section
    ]
    
    def __init__(self):
        """åˆå§‹åŒ–å…ƒæ•°æ®æå–å™¨"""
        logger.info("ðŸ“‹ å…ƒæ•°æ®æå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def extract_from_path(self, file_path: str) -> Dict[str, Any]:
        """
        ä»Žæ–‡ä»¶è·¯å¾„æå–å…ƒæ•°æ®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: æå–çš„å…ƒæ•°æ®
        """
        path = Path(file_path)
        
        metadata = {
            "file_name": path.name,
            "file_stem": path.stem,
            "file_extension": path.suffix.lower(),
            "file_path": str(path),
            "parent_directory": path.parent.name,
        }
        
        # å°è¯•èŽ·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        try:
            stat = path.stat()
            metadata["modified_time"] = datetime.fromtimestamp(stat.st_mtime).isoformat()
            metadata["file_size_bytes"] = stat.st_size
        except Exception:
            pass
        
        return metadata
    
    def extract_from_content(self, content: str) -> Dict[str, Any]:
        """
        ä»Žæ–‡æ¡£å†…å®¹æå–å…ƒæ•°æ®
        
        Args:
            content: æ–‡æ¡£å†…å®¹
            
        Returns:
            Dict: æå–çš„å…ƒæ•°æ®
        """
        metadata = {}
        
        # æå–æ—¥æœŸ
        dates = self._extract_dates(content)
        if dates:
            metadata["extracted_dates"] = dates
            metadata["first_date"] = dates[0]
        
        # æå–æ ‡é¢˜ï¼ˆä»Ž Markdown æ ¼å¼ï¼‰
        headers = self._extract_headers(content)
        if headers:
            metadata["headers"] = headers[:5]  # åªä¿ç•™å‰ 5 ä¸ªæ ‡é¢˜
            metadata["title"] = headers[0] if headers else None
        
        # ç»Ÿè®¡ä¿¡æ¯
        metadata["char_count"] = len(content)
        metadata["word_count"] = len(content.split())
        metadata["line_count"] = content.count("\n") + 1
        
        return metadata
    
    def _extract_dates(self, content: str) -> List[str]:
        """æå–æ–‡æ¡£ä¸­çš„æ—¥æœŸ"""
        dates = []
        for pattern in self.DATE_PATTERNS:
            matches = re.findall(pattern, content)
            dates.extend(matches)
        return list(set(dates))[:10]  # åŽ»é‡å¹¶é™åˆ¶æ•°é‡
    
    def _extract_headers(self, content: str) -> List[str]:
        """æå– Markdown æ ‡é¢˜"""
        headers = []
        for line in content.split("\n"):
            for pattern in self.HEADER_PATTERNS:
                match = re.match(pattern, line.strip())
                if match:
                    headers.append(match.group(1).strip())
                    break
        return headers
    
    def enrich_documents(self, documents: List[Document]) -> List[Document]:
        """
        ä¸ºæ–‡æ¡£åˆ—è¡¨æ·»åŠ ä¸°å¯Œçš„å…ƒæ•°æ®
        
        Args:
            documents: åŽŸå§‹æ–‡æ¡£åˆ—è¡¨
            
        Returns:
            List[Document]: æ·»åŠ å…ƒæ•°æ®åŽçš„æ–‡æ¡£åˆ—è¡¨
        """
        enriched = []
        
        for doc in documents:
            # ä»Žè·¯å¾„æå–å…ƒæ•°æ®
            path_metadata = {}
            if "source" in doc.metadata:
                path_metadata = self.extract_from_path(doc.metadata["source"])
            elif "source_file" in doc.metadata:
                path_metadata = self.extract_from_path(doc.metadata["source_file"])
            
            # ä»Žå†…å®¹æå–å…ƒæ•°æ®
            content_metadata = self.extract_from_content(doc.page_content)
            
            # åˆå¹¶å…ƒæ•°æ®
            enriched_metadata = {
                **doc.metadata,
                **path_metadata,
                **content_metadata
            }
            
            enriched_doc = Document(
                page_content=doc.page_content,
                metadata=enriched_metadata
            )
            enriched.append(enriched_doc)
        
        logger.info(f"âœ… å…ƒæ•°æ®å¢žå¼ºå®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£")
        return enriched
    
    def filter_by_metadata(
        self,
        documents: List[Document],
        filters: Dict[str, Any]
    ) -> List[Document]:
        """
        æ ¹æ®å…ƒæ•°æ®è¿‡æ»¤æ–‡æ¡£
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            filters: è¿‡æ»¤æ¡ä»¶ï¼Œä¾‹å¦‚ {"file_extension": ".md"}
            
        Returns:
            List[Document]: è¿‡æ»¤åŽçš„æ–‡æ¡£åˆ—è¡¨
        """
        result = []
        
        for doc in documents:
            match = True
            for key, value in filters.items():
                if key not in doc.metadata:
                    match = False
                    break
                
                doc_value = doc.metadata[key]
                
                # æ”¯æŒåˆ—è¡¨åŒ¹é…
                if isinstance(value, list):
                    if doc_value not in value:
                        match = False
                        break
                else:
                    if doc_value != value:
                        match = False
                        break
            
            if match:
                result.append(doc)
        
        logger.info(f"ðŸ” å…ƒæ•°æ®è¿‡æ»¤: {len(documents)} -> {len(result)} ä¸ªæ–‡æ¡£")
        return result
