"""
Phase 3: æ¶æ„è¿›åŒ– (Modular & Agentic RAG) - ä¸»å…¥å£

æ¼”ç¤º Agentic RAG çš„å®Œæ•´æµç¨‹ï¼š
1. æ™ºèƒ½è·¯ç”± - æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
2. è‡ªåæ€ RAG - ç­”æ¡ˆè´¨é‡è‡ªè¯„ä¼°å’Œè¿­ä»£ä¼˜åŒ–
3. å·¥å…·è°ƒç”¨ - æœç´¢ã€è®¡ç®—ã€ä»£ç æ‰§è¡Œ
4. çˆ¶å­ç´¢å¼• - ç²¾å‡†æ£€ç´¢ + å®Œæ•´ä¸Šä¸‹æ–‡
5. ä¸Šä¸‹æ–‡å‹ç¼© - ç²¾ç®€æ— å…³å†…å®¹
"""

import sys
from pathlib import Path
from loguru import logger

from src.stage_1.config import Config, get_config
from src.stage_1.document_loader import DocumentLoader
from src.stage_1.vectorstore import VectorStoreManager

from src.stage_2.semantic_chunker import SemanticChunker
from src.stage_2.metadata_extractor import MetadataExtractor

from .config import Stage3Config, get_stage3_config
from .agentic_rag_chain import AgenticRAGChain, AgenticRAGResult
from .router import RouteType


def setup_logger():
    """é…ç½® loguru æ—¥å¿—"""
    logger.remove()
    logger.add(
        sys.stderr,
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>",
        level="INFO",
        colorize=True
    )


def load_and_index_documents(
    data_path: str,
    config: Config,
    use_semantic_chunking: bool = True,
    force_resplit: bool = False
) -> list:
    """
    åŠ è½½å¹¶ç´¢å¼•æ–‡æ¡£
    
    Args:
        data_path: æ–‡æ¡£è·¯å¾„
        config: é…ç½®å¯¹è±¡
        use_semantic_chunking: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰åˆ†å—
        force_resplit: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆ†å—
        
    Returns:
        list: åˆ†å—åçš„æ–‡æ¡£åˆ—è¡¨
    """
    # 1. åŠ è½½æ–‡æ¡£
    logger.info("ğŸ“„ å¼€å§‹åŠ è½½æ–‡æ¡£...")
    loader = DocumentLoader()
    documents = loader.load(data_path)
    
    if not documents:
        logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
        return None
    
    # 2. å…ƒæ•°æ®æå–
    logger.info("ğŸ“‹ æå–å…ƒæ•°æ®...")
    metadata_extractor = MetadataExtractor()
    documents = metadata_extractor.enrich_documents(documents)
    
    # 3. åˆ†å—å¤„ç†
    if use_semantic_chunking:
        logger.info("ğŸ§  ä½¿ç”¨è¯­ä¹‰åˆ†å—...")
        try:
            chunker = SemanticChunker(config)
            chunks = chunker.split_documents(
                documents,
                use_cache=True,
                force_resplit=force_resplit
            )
        except Exception as e:
            logger.warning(f"âš ï¸ è¯­ä¹‰åˆ†å—å¤±è´¥ï¼Œå›é€€åˆ°å›ºå®šåˆ†å—: {e}")
            from src.stage_1.chunker import TextChunker
            chunker = TextChunker(config.chunk_size, config.chunk_overlap)
            chunks = chunker.split_documents(
                documents,
                use_cache=True,
                force_resplit=force_resplit
            )
    else:
        logger.info("âœ‚ï¸ ä½¿ç”¨å›ºå®šåˆ†å—...")
        from src.stage_1.chunker import TextChunker
        chunker = TextChunker(config.chunk_size, config.chunk_overlap)
        chunks = chunker.split_documents(
            documents,
            use_cache=True,
            force_resplit=force_resplit
        )
    
    logger.info(f"âœ… åŠ è½½å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£ -> {len(chunks)} ä¸ªåˆ†å—")
    
    return chunks


def print_result(result: AgenticRAGResult, show_details: bool = False):
    """
    æ‰“å°å¤„ç†ç»“æœ
    
    Args:
        result: å¤„ç†ç»“æœ
        show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    print(f"\nğŸ¤– å›ç­”:\n{result.answer}\n")
    
    if show_details:
        print("=" * 50)
        print("ğŸ“Š å¤„ç†è¯¦æƒ…:")
        print(f"  - è·¯ç”±ç±»å‹: {result.route_type.value}")
        print(f"  - ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print(f"  - è¿­ä»£æ¬¡æ•°: {result.iterations}")
        
        if result.tool_used:
            print(f"  - ä½¿ç”¨å·¥å…·: {result.tool_used}")
        
        if result.sources:
            print(f"\nğŸ“š å‚è€ƒæ¥æº ({len(result.sources)} ä¸ª):")
            for i, source in enumerate(result.sources[:3], 1):
                print(f"  [{i}] {source['source']}")
                print(f"      {source['content'][:80]}...")
        
        print(f"\nğŸ”„ æ¨ç†é“¾:")
        for i, step in enumerate(result.reasoning_chain, 1):
            print(f"  {i}. {step}")
        
        print("=" * 50)


def interactive_qa(rag_chain: AgenticRAGChain):
    """
    äº¤äº’å¼é—®ç­”
    
    Args:
        rag_chain: Agentic RAG é“¾å®ä¾‹
    """
    print("\n" + "=" * 60)
    print("ğŸ¤– Agentic RAG é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨")
    print("=" * 60)
    print("è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("è¾“å…¥ 'detail' åˆ‡æ¢è¯¦ç»†ä¿¡æ¯æ¨¡å¼")
    print("è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
    print("-" * 60 + "\n")
    
    show_details = False
    
    while True:
        try:
            question = input("ğŸ‘¤ æ‚¨çš„é—®é¢˜: ").strip()
            
            if not question:
                continue
            
            if question.lower() in ["quit", "exit", "q"]:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            
            if question.lower() == "detail":
                show_details = not show_details
                status = "å¼€å¯" if show_details else "å…³é—­"
                print(f"\nğŸ“Š è¯¦ç»†ä¿¡æ¯æ¨¡å¼å·²{status}\n")
                continue
            
            if question.lower() == "help":
                print("\n" + "=" * 50)
                print("ğŸ” ç³»ç»Ÿèƒ½åŠ›:")
                print("  - çŸ¥è¯†åº“æ£€ç´¢: ä»æ–‡æ¡£ä¸­æŸ¥æ‰¾ä¿¡æ¯")
                print("  - Web æœç´¢: è·å–å®æ—¶äº’è”ç½‘ä¿¡æ¯")
                print("  - æ•°å­¦è®¡ç®—: æ‰§è¡Œæ•°å­¦è¿ç®—")
                print("  - ä»£ç æ‰§è¡Œ: è¿è¡Œ Python ä»£ç ")
                print("  - ç›´æ¥å›ç­”: é€šç”¨é—®é¢˜å›ç­”")
                print("\nğŸ’¡ ç¤ºä¾‹é—®é¢˜:")
                print("  - çŸ¥è¯†åº“: ä»€ä¹ˆæ˜¯ RAGï¼Ÿ")
                print("  - æœç´¢: ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")
                print("  - è®¡ç®—: 123 * 456 ç­‰äºå¤šå°‘ï¼Ÿ")
                print("  - ä»£ç : ç”¨ Python ç”Ÿæˆ 10 ä¸ªéšæœºæ•°")
                print("  - é—²èŠ: ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")
                print("=" * 50 + "\n")
                continue
            
            print("\nğŸ¤” æ­£åœ¨æ€è€ƒï¼ˆä½¿ç”¨ Agentic RAGï¼‰...\n")
            
            result = rag_chain.ask(question)
            print_result(result, show_details)
            
            print("-" * 60 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            logger.error(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}\n")


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    setup_logger()
    
    print("\n" + "=" * 60)
    print("ğŸš€ Phase 3: Agentic RAG æ¶æ„è¿›åŒ–")
    print("=" * 60 + "\n")
    
    # åŠ è½½é…ç½®
    config = get_config()
    stage3_config = get_stage3_config()
    
    # éªŒè¯é…ç½®
    if not config.validate():
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
        return
    
    # è§£æå‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description="Agentic RAG ç³»ç»Ÿ")
    parser.add_argument(
        "--data",
        type=str,
        default="./data/documents",
        help="æ–‡æ¡£è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–ç›®å½•ï¼‰"
    )
    parser.add_argument(
        "--reindex",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ç´¢å¼•æ–‡æ¡£"
    )
    parser.add_argument(
        "--no-semantic",
        action="store_true",
        help="ç¦ç”¨è¯­ä¹‰åˆ†å—"
    )
    parser.add_argument(
        "--no-routing",
        action="store_true",
        help="ç¦ç”¨æ™ºèƒ½è·¯ç”±"
    )
    parser.add_argument(
        "--no-self-rag",
        action="store_true",
        help="ç¦ç”¨è‡ªåæ€"
    )
    parser.add_argument(
        "--no-tools",
        action="store_true",
        help="ç¦ç”¨å·¥å…·è°ƒç”¨"
    )
    parser.add_argument(
        "--no-parent-child",
        action="store_true",
        help="ç¦ç”¨çˆ¶å­ç´¢å¼•"
    )
    parser.add_argument(
        "--no-compression",
        action="store_true",
        help="ç¦ç”¨ä¸Šä¸‹æ–‡å‹ç¼©"
    )
    args = parser.parse_args()
    
    # åŠ è½½æ–‡æ¡£
    data_path = Path(args.data)
    chunks = None
    vectorstore_manager = VectorStoreManager(config, collection_name="agentic_rag")
    
    if args.reindex or vectorstore_manager.vectorstore._collection.count() == 0:
        if data_path.exists():
            chunks = load_and_index_documents(
                str(data_path),
                config,
                use_semantic_chunking=not args.no_semantic,
                force_resplit=args.reindex
            )
            if chunks is None:
                return
            # å°†åˆ†å—å­˜å…¥å‘é‡åº“
            vectorstore_manager.add_documents(chunks)
        else:
            logger.warning(f"âš ï¸ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")
            logger.info("ğŸ’¡ è¯·åˆ›å»º ./data/documents ç›®å½•å¹¶æ”¾å…¥æ–‡æ¡£")
            return
    else:
        logger.info(f"ğŸ“¦ ä½¿ç”¨å·²æœ‰å‘é‡åº“")
        # å°è¯•ä»ç¼“å­˜åŠ è½½åˆ†å—
        if data_path.exists():
            loader = DocumentLoader()
            docs = loader.load(str(data_path))
            if not args.no_semantic:
                try:
                    chunker = SemanticChunker(config)
                    chunks = chunker.split_documents(docs, use_cache=True)
                except Exception:
                    from src.stage_1.chunker import TextChunker
                    chunker = TextChunker(config.chunk_size, config.chunk_overlap)
                    chunks = chunker.split_documents(docs)
            else:
                from src.stage_1.chunker import TextChunker
                chunker = TextChunker(config.chunk_size, config.chunk_overlap)
                chunks = chunker.split_documents(docs)
    
    # åˆ›å»º Agentic RAG é“¾
    rag_chain = AgenticRAGChain(
        documents=chunks,
        vectorstore_manager=vectorstore_manager,
        config=stage3_config,
        enable_routing=not args.no_routing,
        enable_self_rag=not args.no_self_rag,
        enable_tools=not args.no_tools,
        enable_parent_child=not args.no_parent_child,
        enable_compression=not args.no_compression,
        force_reindex=args.reindex
    )
    
    # å¯åŠ¨äº¤äº’
    interactive_qa(rag_chain)


if __name__ == "__main__":
    main()

