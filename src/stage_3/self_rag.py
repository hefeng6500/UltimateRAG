"""
Self-RAG (è‡ªåæ€ RAG) æ¨¡å—

å®ç°ç­”æ¡ˆè´¨é‡è‡ªè¯„ä¼°å’Œè¿­ä»£ä¼˜åŒ–ï¼š
1. æ£€ç´¢ç›¸å…³æ€§è¯„ä¼° - åˆ¤æ–­æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯å¦ç›¸å…³
2. ç­”æ¡ˆè´¨é‡è¯„ä¼° - åˆ¤æ–­ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯å¦å®Œæ•´å‡†ç¡®
3. è¿­ä»£æ£€ç´¢ - è´¨é‡ä¸è¶³æ—¶é‡æ–°æ£€ç´¢
"""

from typing import List, Optional, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum
from loguru import logger

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

from .config import Stage3Config, get_stage3_config


class RelevanceGrade(str, Enum):
    """æ£€ç´¢ç›¸å…³æ€§ç­‰çº§"""
    HIGHLY_RELEVANT = "highly_relevant"  # é«˜åº¦ç›¸å…³
    PARTIALLY_RELEVANT = "partially_relevant"  # éƒ¨åˆ†ç›¸å…³
    NOT_RELEVANT = "not_relevant"  # ä¸ç›¸å…³


class QualityGrade(str, Enum):
    """ç­”æ¡ˆè´¨é‡ç­‰çº§"""
    EXCELLENT = "excellent"  # ä¼˜ç§€
    ACCEPTABLE = "acceptable"  # å¯æ¥å—
    NEEDS_IMPROVEMENT = "needs_improvement"  # éœ€è¦æ”¹è¿›
    INSUFFICIENT = "insufficient"  # ä¸è¶³


class RelevanceEvaluation(BaseModel):
    """æ£€ç´¢ç›¸å…³æ€§è¯„ä¼°ç»“æœ"""
    grade: RelevanceGrade = Field(description="ç›¸å…³æ€§ç­‰çº§")
    score: float = Field(description="ç›¸å…³æ€§åˆ†æ•° 0-1", ge=0.0, le=1.0)
    reasoning: str = Field(description="è¯„ä¼°åŸå› ")


class QualityEvaluation(BaseModel):
    """ç­”æ¡ˆè´¨é‡è¯„ä¼°ç»“æœ"""
    grade: QualityGrade = Field(description="è´¨é‡ç­‰çº§")
    score: float = Field(description="è´¨é‡åˆ†æ•° 0-1", ge=0.0, le=1.0)
    is_complete: bool = Field(description="ç­”æ¡ˆæ˜¯å¦å®Œæ•´")
    is_accurate: bool = Field(description="ç­”æ¡ˆæ˜¯å¦å‡†ç¡®")
    missing_info: str = Field(description="ç¼ºå¤±çš„ä¿¡æ¯æè¿°")
    suggestions: str = Field(description="æ”¹è¿›å»ºè®®")


@dataclass
class SelfRAGResult:
    """Self-RAG å¤„ç†ç»“æœ"""
    answer: str
    documents: List[Document]
    iterations: int
    relevance_scores: List[float]
    quality_score: float
    quality_grade: QualityGrade
    reasoning_chain: List[str]


# ç›¸å…³æ€§è¯„ä¼°æç¤ºè¯
RELEVANCE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°ä¸“å®¶ã€‚
è¯„ä¼°ç»™å®šæ–‡æ¡£ä¸ç”¨æˆ·é—®é¢˜çš„ç›¸å…³ç¨‹åº¦ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

å¾…è¯„ä¼°æ–‡æ¡£ï¼š
{document}

è¯„ä¼°æ ‡å‡†ï¼š
- highly_relevant: æ–‡æ¡£ç›´æ¥å›ç­”äº†é—®é¢˜çš„æ ¸å¿ƒå†…å®¹
- partially_relevant: æ–‡æ¡£åŒ…å«ä¸€äº›ç›¸å…³ä¿¡æ¯ï¼Œä½†ä¸å®Œæ•´
- not_relevant: æ–‡æ¡£ä¸é—®é¢˜åŸºæœ¬æ— å…³

è¯·ç»™å‡ºä½ çš„è¯„ä¼°ã€‚"""

# è´¨é‡è¯„ä¼°æç¤ºè¯
QUALITY_PROMPT = """ä½ æ˜¯ä¸€ä¸ªç­”æ¡ˆè´¨é‡è¯„ä¼°ä¸“å®¶ã€‚
è¯„ä¼°ç»™å®šç­”æ¡ˆå¯¹ç”¨æˆ·é—®é¢˜çš„å›ç­”è´¨é‡ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{question}

å‚è€ƒæ–‡æ¡£ï¼š
{context}

ç”Ÿæˆçš„ç­”æ¡ˆï¼š
{answer}

è¯„ä¼°æ ‡å‡†ï¼š
- excellent: ç­”æ¡ˆå®Œæ•´ã€å‡†ç¡®ã€æœ‰æ¡ç†ï¼Œå®Œå…¨è§£ç­”äº†é—®é¢˜
- acceptable: ç­”æ¡ˆåŸºæœ¬æ­£ç¡®ï¼Œä½†å¯èƒ½é—æ¼ä¸€äº›ç»†èŠ‚
- needs_improvement: ç­”æ¡ˆéƒ¨åˆ†æ­£ç¡®ï¼Œä½†æœ‰æ˜æ˜¾é—æ¼æˆ–ä¸å‡†ç¡®
- insufficient: ç­”æ¡ˆä¸èƒ½æœ‰æ•ˆå›ç­”é—®é¢˜

è¯·ç»™å‡ºè¯¦ç»†çš„è´¨é‡è¯„ä¼°ã€‚"""

# æŸ¥è¯¢ä¼˜åŒ–æç¤ºè¯
QUERY_REFINEMENT_PROMPT = """åŸºäºå½“å‰çš„æ£€ç´¢ç»“æœä¸å¤Ÿç†æƒ³ï¼Œè¯·å¸®æˆ‘ä¼˜åŒ–æœç´¢æŸ¥è¯¢ã€‚

åŸå§‹é—®é¢˜ï¼š{question}

å½“å‰æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼š
{current_info}

ç¼ºå¤±çš„ä¿¡æ¯ï¼š
{missing_info}

è¯·ç”Ÿæˆä¸€ä¸ªæ›´ç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ï¼Œç”¨äºæ‰¾åˆ°ç¼ºå¤±çš„ä¿¡æ¯ã€‚åªè¾“å‡ºæ–°çš„æŸ¥è¯¢è¯­å¥ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""


class SelfRAG:
    """
    è‡ªåæ€ RAG
    
    å®ç° RAG ç­”æ¡ˆçš„è‡ªæˆ‘è¯„ä¼°å’Œè¿­ä»£ä¼˜åŒ–ã€‚
    æ ¸å¿ƒæµç¨‹ï¼šæ£€ç´¢ -> è¯„ä¼°ç›¸å…³æ€§ -> ç”Ÿæˆç­”æ¡ˆ -> è¯„ä¼°è´¨é‡ -> å¿…è¦æ—¶è¿­ä»£
    """
    
    def __init__(self, config: Optional[Stage3Config] = None):
        """
        åˆå§‹åŒ– Self-RAG
        
        Args:
            config: Stage3 é…ç½®
        """
        self.config = config or get_stage3_config()
        self._llm = self._create_llm()
        self._relevance_evaluator = self._llm.with_structured_output(RelevanceEvaluation)
        self._quality_evaluator = self._llm.with_structured_output(QualityEvaluation)
        
        logger.info("ğŸ”„ Self-RAG åˆå§‹åŒ–å®Œæˆ")
    
    def _create_llm(self) -> ChatOpenAI:
        """åˆ›å»º LLM å®ä¾‹"""
        kwargs = {
            "model": self.config.model_name,
            "api_key": self.config.openai_api_key,
            "temperature": 0.1,
        }
        if self.config.openai_base_url:
            kwargs["base_url"] = self.config.openai_base_url
        return ChatOpenAI(**kwargs)
    
    def evaluate_relevance(
        self, 
        question: str, 
        document: Document
    ) -> RelevanceEvaluation:
        """
        è¯„ä¼°å•ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            document: å¾…è¯„ä¼°æ–‡æ¡£
            
        Returns:
            RelevanceEvaluation: ç›¸å…³æ€§è¯„ä¼°ç»“æœ
        """
        prompt = ChatPromptTemplate.from_template(RELEVANCE_PROMPT)
        
        try:
            result = self._relevance_evaluator.invoke(
                prompt.format(
                    question=question,
                    document=document.page_content[:1000]
                )
            )
            return result
        except Exception as e:
            logger.warning(f"âš ï¸ ç›¸å…³æ€§è¯„ä¼°å¤±è´¥: {e}")
            return RelevanceEvaluation(
                grade=RelevanceGrade.PARTIALLY_RELEVANT,
                score=0.5,
                reasoning="è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼"
            )
    
    def filter_relevant_documents(
        self,
        question: str,
        documents: List[Document],
        threshold: float = None
    ) -> Tuple[List[Document], List[float]]:
        """
        è¿‡æ»¤ç›¸å…³æ–‡æ¡£
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            documents: æ–‡æ¡£åˆ—è¡¨
            threshold: ç›¸å…³æ€§é˜ˆå€¼
            
        Returns:
            Tuple[List[Document], List[float]]: (è¿‡æ»¤åçš„æ–‡æ¡£, ç›¸å…³æ€§åˆ†æ•°)
        """
        threshold = threshold or self.config.self_rag_relevance_threshold
        
        filtered_docs = []
        scores = []
        
        for doc in documents:
            evaluation = self.evaluate_relevance(question, doc)
            
            if evaluation.score >= threshold:
                filtered_docs.append(doc)
                scores.append(evaluation.score)
                logger.debug(
                    f"  âœ… ä¿ç•™æ–‡æ¡£ (åˆ†æ•°: {evaluation.score:.2f}): "
                    f"{doc.page_content[:50]}..."
                )
            else:
                logger.debug(
                    f"  âŒ è¿‡æ»¤æ–‡æ¡£ (åˆ†æ•°: {evaluation.score:.2f}): "
                    f"{doc.page_content[:50]}..."
                )
        
        logger.info(
            f"ğŸ” ç›¸å…³æ€§è¿‡æ»¤: {len(documents)} -> {len(filtered_docs)} ä¸ªæ–‡æ¡£"
        )
        
        return filtered_docs, scores
    
    def evaluate_answer_quality(
        self,
        question: str,
        context: str,
        answer: str
    ) -> QualityEvaluation:
        """
        è¯„ä¼°ç­”æ¡ˆè´¨é‡
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: å‚è€ƒä¸Šä¸‹æ–‡
            answer: ç”Ÿæˆçš„ç­”æ¡ˆ
            
        Returns:
            QualityEvaluation: è´¨é‡è¯„ä¼°ç»“æœ
        """
        prompt = ChatPromptTemplate.from_template(QUALITY_PROMPT)
        
        try:
            result = self._quality_evaluator.invoke(
                prompt.format(
                    question=question,
                    context=context[:2000],
                    answer=answer
                )
            )
            
            logger.info(
                f"ğŸ“Š ç­”æ¡ˆè´¨é‡è¯„ä¼°: {result.grade.value} "
                f"(åˆ†æ•°: {result.score:.2f})"
            )
            
            return result
        except Exception as e:
            logger.warning(f"âš ï¸ è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return QualityEvaluation(
                grade=QualityGrade.ACCEPTABLE,
                score=0.6,
                is_complete=True,
                is_accurate=True,
                missing_info="",
                suggestions=""
            )
    
    def refine_query(
        self,
        question: str,
        current_info: str,
        missing_info: str
    ) -> str:
        """
        ä¼˜åŒ–æœç´¢æŸ¥è¯¢
        
        Args:
            question: åŸå§‹é—®é¢˜
            current_info: å½“å‰æ£€ç´¢åˆ°çš„ä¿¡æ¯
            missing_info: ç¼ºå¤±çš„ä¿¡æ¯æè¿°
            
        Returns:
            str: ä¼˜åŒ–åçš„æŸ¥è¯¢
        """
        prompt = ChatPromptTemplate.from_template(QUERY_REFINEMENT_PROMPT)
        
        try:
            response = self._llm.invoke(
                prompt.format(
                    question=question,
                    current_info=current_info[:500],
                    missing_info=missing_info
                )
            )
            refined_query = response.content.strip()
            logger.info(f"ğŸ”„ æŸ¥è¯¢ä¼˜åŒ–: {question[:30]}... -> {refined_query[:30]}...")
            return refined_query
        except Exception as e:
            logger.warning(f"âš ï¸ æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥: {e}")
            return question
    
    def should_iterate(self, quality_eval: QualityEvaluation) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦è¿­ä»£
        
        Args:
            quality_eval: è´¨é‡è¯„ä¼°ç»“æœ
            
        Returns:
            bool: æ˜¯å¦éœ€è¦è¿­ä»£
        """
        # è´¨é‡ä¸è¶³ä¸”æœ‰ç¼ºå¤±ä¿¡æ¯æ—¶éœ€è¦è¿­ä»£
        return (
            quality_eval.score < self.config.self_rag_quality_threshold
            and quality_eval.missing_info
            and quality_eval.grade in [
                QualityGrade.NEEDS_IMPROVEMENT,
                QualityGrade.INSUFFICIENT
            ]
        )
    
    def generate_answer(
        self,
        question: str,
        context: str
    ) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: å‚è€ƒä¸Šä¸‹æ–‡
            
        Returns:
            str: ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        prompt = ChatPromptTemplate.from_template(
            """åŸºäºä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ã€‚

å‚è€ƒæ–‡æ¡£ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š"""
        )
        
        response = self._llm.invoke(
            prompt.format(context=context, question=question)
        )
        return response.content

