"""
åµŒå…¥æ¨¡å‹æ¨¡å—

å°è£… Embedding æ¨¡å‹ï¼Œæ”¯æŒ OpenAI å’Œæœ¬åœ°æ¨¡å‹ã€‚
ç”¨äºå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚
"""

from typing import List, Optional
from loguru import logger

from langchain_core.embeddings import Embeddings
from langchain_openai import OpenAIEmbeddings

from .config import Config, get_config


# é˜¿é‡Œäº‘ Embedding API çš„æ‰¹é‡å¤§å°é™åˆ¶
ALIYUN_EMBEDDING_BATCH_SIZE = 10


class BatchedEmbeddings(Embeddings):
    """
    æ‰¹é‡åµŒå…¥åŒ…è£…å™¨
    
    ç”¨äºè§£å†³é˜¿é‡Œäº‘ç­‰ API æä¾›å•†çš„æ‰¹é‡å¤§å°é™åˆ¶é—®é¢˜ã€‚
    å°†å¤§æ‰¹é‡æ–‡æœ¬æ‹†åˆ†æˆå¤šä¸ªå°æ‰¹æ¬¡åˆ†åˆ«è°ƒç”¨ï¼Œç„¶ååˆå¹¶ç»“æœã€‚
    
    é˜¿é‡Œäº‘å…¼å®¹ OpenAI çš„ Embedding æ¥å£é™åˆ¶æ¯æ¬¡è¯·æ±‚æœ€å¤š 10 æ¡æ–‡æœ¬ã€‚
    """
    
    def __init__(self, inner: Embeddings, batch_size: int = ALIYUN_EMBEDDING_BATCH_SIZE):
        """
        åˆå§‹åŒ–æ‰¹é‡åµŒå…¥åŒ…è£…å™¨
        
        Args:
            inner: å†…éƒ¨çš„åµŒå…¥æ¨¡å‹å®ä¾‹ï¼ˆå¦‚ OpenAIEmbeddingsï¼‰
            batch_size: æ¯æ‰¹æ¬¡æœ€å¤§æ–‡æœ¬æ•°é‡ï¼Œé»˜è®¤ 10ï¼ˆé˜¿é‡Œäº‘é™åˆ¶ï¼‰
        """
        self.inner = inner
        self.batch_size = batch_size
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡åµŒå…¥æ–‡æ¡£ï¼ˆåˆ†æ‰¹è°ƒç”¨ï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            List[List[float]]: å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
        
        all_embeddings: List[List[float]] = []
        total_batches = (len(texts) + self.batch_size - 1) // self.batch_size
        
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i : i + self.batch_size]
            current_batch = i // self.batch_size + 1
            
            logger.debug(
                f"ğŸ“¦ åµŒå…¥æ‰¹æ¬¡ {current_batch}/{total_batches}: "
                f"å¤„ç† {len(batch)} æ¡æ–‡æœ¬"
            )
            
            # è°ƒç”¨å†…éƒ¨åµŒå…¥æ¨¡å‹
            batch_embeddings = self.inner.embed_documents(batch)
            all_embeddings.extend(batch_embeddings)
        
        logger.debug(f"âœ… æ‰¹é‡åµŒå…¥å®Œæˆ: å…± {len(texts)} æ¡æ–‡æœ¬ï¼Œåˆ† {total_batches} æ‰¹å¤„ç†")
        return all_embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """
        åµŒå…¥å•æ¡æŸ¥è¯¢ï¼ˆç›´æ¥è°ƒç”¨å†…éƒ¨æ¨¡å‹ï¼‰
        
        Args:
            text: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            List[float]: æŸ¥è¯¢å‘é‡
        """
        # æŸ¥è¯¢åªæœ‰ä¸€æ¡ï¼Œä¸éœ€è¦åˆ†æ‰¹ï¼Œç›´æ¥é€ä¼ 
        return self.inner.embed_query(text)


class EmbeddingModel:
    """
    åµŒå…¥æ¨¡å‹å°è£…ç±»
    
    æ”¯æŒ OpenAI Embeddings å’Œæœ¬åœ° HuggingFace æ¨¡å‹ã€‚
    Phase 1 é»˜è®¤ä½¿ç”¨ OpenAI text-embedding-3-smallã€‚
    """
    
    def __init__(self, config: Optional[Config] = None):
        """
        åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸º None åˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½
        """
        self.config = config or get_config()
        self._embeddings: Optional[Embeddings] = None
        
    @property
    def embeddings(self) -> Embeddings:
        """
        è·å–åµŒå…¥æ¨¡å‹å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
        
        Returns:
            Embeddings: LangChain åµŒå…¥æ¨¡å‹å®ä¾‹
        """
        if self._embeddings is None:
            self._embeddings = self._create_embeddings()
        return self._embeddings
    
    def _create_embeddings(self) -> Embeddings:
        """
        åˆ›å»ºåµŒå…¥æ¨¡å‹å®ä¾‹
        
        ä½¿ç”¨ BatchedEmbeddings åŒ…è£…å™¨æ¥è§£å†³é˜¿é‡Œäº‘ç­‰ API çš„æ‰¹é‡å¤§å°é™åˆ¶ã€‚
        
        Returns:
            Embeddings: LangChain åµŒå…¥æ¨¡å‹å®ä¾‹ï¼ˆå·²åŒ…è£…åˆ†æ‰¹å¤„ç†ï¼‰
        """
        model_name = self.config.embedding_model
        
        # ä½¿ç”¨ OpenAI Embeddings
        kwargs = {
            "model": model_name,
            "api_key": self.config.openai_api_key,
            "check_embedding_ctx_length": False,  # é˜¿é‡Œäº‘å…¼å®¹æ¨¡å¼éœ€è¦å…³é—­
        }
        
        # å¦‚æœè®¾ç½®äº†è‡ªå®šä¹‰ base_urlï¼ˆå¦‚é˜¿é‡Œäº‘ DashScopeï¼‰ï¼Œåˆ™ä½¿ç”¨
        if self.config.openai_base_url:
            kwargs["base_url"] = self.config.openai_base_url
        
        base_embeddings = OpenAIEmbeddings(**kwargs)
        
        # ä½¿ç”¨ BatchedEmbeddings åŒ…è£…ï¼Œè‡ªåŠ¨åˆ†æ‰¹å¤„ç†ï¼ˆæ¯æ‰¹æœ€å¤š 10 æ¡ï¼‰
        embeddings = BatchedEmbeddings(inner=base_embeddings, batch_size=ALIYUN_EMBEDDING_BATCH_SIZE)
        
        logger.info(f"ğŸ”¢ åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {model_name} (æ‰¹é‡å¤§å°: {ALIYUN_EMBEDDING_BATCH_SIZE})")
        return embeddings
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡åµŒå…¥æ–‡æ¡£
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            List[List[float]]: å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []
        
        vectors = self.embeddings.embed_documents(texts)
        logger.debug(f"âœ… å·²åµŒå…¥ {len(texts)} ä¸ªæ–‡æ¡£ï¼Œå‘é‡ç»´åº¦: {len(vectors[0])}")
        return vectors
    
    def embed_query(self, text: str) -> List[float]:
        """
        åµŒå…¥æŸ¥è¯¢æ–‡æœ¬
        
        Args:
            text: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            List[float]: æŸ¥è¯¢å‘é‡
        """
        vector = self.embeddings.embed_query(text)
        logger.debug(f"âœ… å·²åµŒå…¥æŸ¥è¯¢ï¼Œå‘é‡ç»´åº¦: {len(vector)}")
        return vector
