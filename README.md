# 从入门到精通的 RAG 开发路线图（Roadmap）

分为五个阶段，从最简单的 Demo 进化到企业级、甚至科研级的 RAG 系统。

---

### **阶段一：原型验证 (MVP) —— "Hello World" 级别**

**目标：** 跑通流程，构建一个能用的问答机器人。
**核心理念：** 先有再优（Make it work）。

1.  **基础架构搭建：**

    - **Orchestration (编排框架):** 选择 **LangChain** 或 **LlamaIndex**（推荐 LlamaIndex，更专注于数据索引优化）。
    - **LLM:** 直接调用 API（OpenAI GPT-4o 或 DeepSeek/Qwen 等国产优秀模型），暂不考虑本地部署。
    - **Vector DB (向量库):** 使用轻量级的 **Chroma** 或 **FAISS**，本地运行即可。
    - **Embedding Model:** 使用通用的 OpenAI `text-embedding-3-small` 或 HuggingFace 上的 `bge-m3`。

2.  **实现步骤：**
    - **数据清洗:** 将文档（PDF/Markdown）转为纯文本。
    - **基础分块:** 使用 `FixedSizeChunking`（例如 512 token 一个块，重叠 50 token）。
    - **存取与生成:** 用户提问 -> 向量检索 Top-3 -> 塞入 Prompt -> LLM 回答。

**✅ 阶段成果：** 一个能回答简单文档问题的 Bot，但经常答非所问，或者因为切片太碎丢失上下文。

---

### **阶段二：质量飞跃 (Advanced RAG) —— 解决“检索不准”**

**目标：** 大幅提升检索的准确率（Precision）和召回率（Recall）。这是 80% 的 RAG 开发者目前所处的阶段。
**核心理念：** 优化检索链路的每一个环节。

1.  **数据层优化 (Indexing):**

    - **语义分块 (Semantic Chunking):** 不再按固定字数切，而是根据语义完整性切分（例如一个完整的段落或函数）。
    - **元数据提取 (Metadata Extraction):** 提取文件名、页码、日期、作者，用于后续的过滤（Filtering）。例如：“只检索 2024 年之后的文件”。

2.  **检索层升级 (Retrieval):**

    - **混合检索 (Hybrid Search):** 引入 **BM25（关键词检索）** + **向量检索**。解决“搜专有名词（如 SK-1024）搜不到”的问题。
    - **Query Rewrite (查询重写):**
      - _多路查询:_ 把用户的“它性能怎么样？”改写为“SK-1024 的性能参数”，并生成 3 个变体并行搜索。
      - _HyDE:_ 让 LLM 先生成一个假答案，用假答案去搜真文档。

3.  **检索后处理 (Post-Retrieval) —— **必做项**:**
    - **Re-ranking (重排序):** 检索出 Top-50 个粗略结果，用 **BGE-Reranker** 或 **Cohere Rerank** 模型进行精细排序，只取前 5 个给 LLM。这是提升效果最明显的“银弹”。

**✅ 阶段成果：** 回答准确率大幅提升，不再容易因为关键词匹配不上而瞎编。

---

### **阶段三：架构进化 (Modular & Agentic RAG) —— 解决“逻辑复杂”**

**目标：** 让系统具备“思考”能力，处理复杂任务（不仅仅是找文档）。
**核心理念：** RAG 不再是一条直线，而是一个动态的网络。

1.  **路由机制 (Routing):**

    - 根据问题分类：技术问题 -> 查技术手册库；价格问题 -> 查 SQL 数据库；闲聊 -> 直接回答。

2.  **Agentic RAG (代理式 RAG):**

    - **Self-RAG (自反思 RAG):** LLM 生成答案后，自己给自己打分。如果觉得检索到的内容不够回答问题，它会主动发起**第二次检索**。
    - **Tool Use (工具调用):** 让 RAG 系统拥有调用 Google 搜索、Calculator（计算器）或 Python 解释器的能力。

3.  **高级上下文管理:**
    - **Parent-Child Indexing (父子索引):** 检索时匹配小的“子块”（精准），给 LLM 时送入大的“父块”（上下文完整）。
    - **Context Compression:** 像“挤牙膏”一样，把检索到的文档里没用的废话删掉，只保留核心句子给 LLM，节省 Token。

**✅ 阶段成果：** 系统变“聪明”了，懂得拒绝回答（如果没搜到），懂得自己去网上找补充信息，能处理多步推理问题。

---

### **阶段四：最强形态 (GraphRAG & Fine-tuning) —— 解决“深度认知”**

**目标：** 拥有上帝视角，理解数据之间的隐性关联，并在此垂直领域达到专家级水平。
**核心理念：** 结构化知识 + 领域适配。

1.  **引入知识图谱 (GraphRAG):**

    - **技术栈:** Neo4j, NebulaGraph, 微软 GraphRAG。
    - **场景:** 适合法律、金融、刑侦。比如：“找出 A 公司和 B 公司之间所有的资金往来路径”。向量检索对此无能为力，必须靠图谱。
    - **实现:** 用 LLM 自动从文本中抽取实体（Entity）和关系（Relation）建图。检索时进行**图遍历**。

2.  **领域微调 (Fine-tuning):**
    - **Embedding 微调:** 如果你的领域有很多黑话（如医疗、半导体），通用的 Embedding 模型可能无法理解两个词的相似性。需要用私有数据微调 BGE 等模型。
    - **LLM 微调:** 让模型学会特定的回复风格（如“像个严谨的律师一样说话”）。

**✅ 阶段成果：** 能够回答跨文档的、全局性的概括问题（如“总结全公司过去三年在 AI 方面的战略变化”），这是目前 RAG 的天花板。

---

### **阶段五：工业级运维 (RAGOps) —— 持续迭代**

**目标：** 监控系统健康度，量化评估效果。
**核心理念：** 不能度量，就不能优化。

1.  **评估框架 (Evaluation):**

    - 搭建 **RAGAS** 或 **TruLens**。
    - 构建“黄金数据集”（Golden Dataset）：即准备 100 个高质量的“问题-标准答案”对，每次更新代码后自动跑一遍测试。

2.  **可观测性 (Observability):**
    - 使用 **LangSmith** 或 **Arize Phoenix**。
    - 记录每一次检索的耗时、Token 消耗、检索到的 Chunk 内容，方便由于 Bad Case（错误回答）时回溯排查。

---

### **总结：一步一步怎么走？**

| 阶段        | 预计耗时 | 关键动作                        | 标志性技术                                 |
| :---------- | :------- | :------------------------------ | :----------------------------------------- |
| **Phase 1** | 1 周     | 跑通 LlamaIndex + OpenAI        | Naive RAG, Vector DB                       |
| **Phase 2** | 2-4 周   | **加 Re-ranking**，搞定混合检索 | Hybrid Search, Reranker, Semantic Chunking |
| **Phase 3** | 1-2 月   | 引入 Agent 逻辑，让它会反思     | Self-RAG, Routing, Tool Use                |
| **Phase 4** | 2-3 月+  | 构建知识图谱，微调模型          | **GraphRAG**, Fine-tuning                  |
| **Phase 5** | 持续     | 建立自动化测试流水线            | RAGAS, LangSmith                           |

**我的建议：**
不要一开始就做 GraphRAG，太复杂且成本高。请从 **Phase 2 (Advanced RAG)** 扎实做起，尤其是 **Re-ranking** 和 **混合检索**，这两项是投入产出比（ROI）最高的技术。
