# æœ¬åœ° LLM å¾®è°ƒæŒ‡å—

## ğŸ“– æ¦‚è¿°

æœ¬æ¨¡å—æä¾›äº†åœ¨æœ¬åœ°è®¾å¤‡ä¸Šè¿›è¡Œ LLM å¾®è°ƒçš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚ä½¿ç”¨ **LoRA (Low-Rank Adaptation)** æŠ€æœ¯ï¼Œå¯ä»¥åœ¨æœ‰é™çš„ç¡¬ä»¶èµ„æºä¸‹é«˜æ•ˆå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚

### æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **ä½èµ„æºéœ€æ±‚** | LoRA ä»…è®­ç»ƒçº¦ 0.1%-1% çš„å‚æ•°ï¼Œå¤§å¹…é™ä½å†…å­˜éœ€æ±‚ |
| **å¤šè®¾å¤‡æ”¯æŒ** | æ”¯æŒ CPU / CUDA / MPS (Apple Silicon) |
| **ä¸»æµæ¨¡å‹** | æ”¯æŒ Qwenã€LLaMAã€Mistral ç­‰å¼€æºæ¨¡å‹ |
| **æ•°æ®å¤ç”¨** | ç›´æ¥ä½¿ç”¨å·²ç”Ÿæˆçš„ Alpaca æ ¼å¼è®­ç»ƒæ•°æ® |
| **ä¸€é”®å¾®è°ƒ** | æä¾›å‘½ä»¤è¡Œå·¥å…·å’Œ Python API |
| **äº¤äº’å¯¹è¯** | å¾®è°ƒå®Œæˆåå¯ç›´æ¥è¿›è¡Œäº¤äº’å¼é—®ç­” |

---

## ğŸ–¥ï¸ ç¡¬ä»¶è¦æ±‚

### æœ€ä½é…ç½®

| é…ç½®é¡¹ | CPU è®­ç»ƒ | GPU è®­ç»ƒ |
|--------|----------|----------|
| å†…å­˜/æ˜¾å­˜ | 16GB RAM | 8GB VRAM |
| æ¨èæ¨¡å‹ | 0.5B-1.5B | 1.5B-7B |
| è®­ç»ƒé€Ÿåº¦ | è¾ƒæ…¢ | å¿« |

### æ¨èæ¨¡å‹é€‰æ‹©

| ç¡¬ä»¶é…ç½® | æ¨èæ¨¡å‹ | é¢„ä¼°æ—¶é—´/epoch |
|----------|----------|----------------|
| 16GB RAM (CPU) | Qwen2.5-0.5B-Instruct | ~30åˆ†é’Ÿ |
| 16GB RAM (CPU) | Qwen2.5-1.5B-Instruct | ~60åˆ†é’Ÿ |
| 8GB VRAM (GPU) | Qwen2.5-1.5B-Instruct | ~5åˆ†é’Ÿ |
| 16GB VRAM (GPU) | Qwen2.5-7B-Instruct | ~10åˆ†é’Ÿ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install torch transformers peft datasets accelerate trl
```

æˆ–ä½¿ç”¨é¡¹ç›®çš„ requirements.txtï¼š

```bash
pip install -r requirements.txt
```

### 2. å‘½ä»¤è¡Œä¸€é”®å¾®è°ƒ â­

**æœ€ç®€å•çš„æ–¹å¼ - ä¸€è¡Œå‘½ä»¤å®Œæˆå¾®è°ƒï¼š**

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œå¾®è°ƒ
python -m src.stage_4.finetune_main train

# æŒ‡å®šæ¨¡å‹å’Œå‚æ•°
python -m src.stage_4.finetune_main train --model Qwen/Qwen2.5-0.5B-Instruct --epochs 3

# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‚æ•°
python -m src.stage_4.finetune_main train --help
```

### 3. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹å¯¹è¯ â­

```bash
# å¯åŠ¨äº¤äº’å¼å¯¹è¯
python -m src.stage_4.finetune_main chat

# æŒ‡å®šæ¨¡å‹è·¯å¾„
python -m src.stage_4.finetune_main chat --model-path ./models/finetuned_llm/adapter
```

### 4. æµ‹è¯•æ¨¡å‹æ•ˆæœ

```bash
# è¿è¡Œé¢„è®¾æµ‹è¯•é—®é¢˜
python -m src.stage_4.finetune_main test

# å¯¹æ¯”å¾®è°ƒå‰åæ•ˆæœ
python -m src.stage_4.finetune_main compare
```

### 5. Python API æ–¹å¼

```python
from src.stage_4.fine_tuning import quick_finetune

# ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œå¾®è°ƒ
result = quick_finetune(
    data_path="./data/finetune/train_alpaca.json",
    model="Qwen/Qwen2.5-0.5B-Instruct",
    epochs=3
)

print(f"è®­ç»ƒæŸå¤±: {result['metrics']['train_loss']}")
print(f"æµ‹è¯•å›å¤: {result['test_response']}")
```

### 6. ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ (Python)

```python
from src.stage_4.fine_tuning import LocalLLMFineTuner

# åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
finetuner = LocalLLMFineTuner()
finetuner.load_adapter(
    adapter_path="./models/finetuned_llm/adapter",
    base_model_path="Qwen/Qwen2.5-0.5B-Instruct"
)

# è¿›è¡Œå¯¹è¯
response = finetuner.chat("å°ç±³å…¬å¸æ˜¯ä»€ä¹ˆæ—¶å€™æˆç«‹çš„ï¼Ÿ")
print(response)
```

---

## ğŸ“š è¯¦ç»†ä½¿ç”¨æŒ‡å—

### å®Œæ•´å¾®è°ƒæµç¨‹

```python
from src.stage_4.fine_tuning import LocalLLMFineTuner, LocalFineTuneConfig

# 1. åˆ›å»ºé…ç½®
config = LocalFineTuneConfig(
    # æ¨¡å‹é…ç½®
    base_model="Qwen/Qwen2.5-1.5B-Instruct",
    output_dir="./models/my_finetuned_model",
    
    # LoRA é…ç½®
    lora_rank=8,          # ç§©è¶Šå°ï¼Œå‚æ•°è¶Šå°‘ï¼Œæ¨è 4-16
    lora_alpha=16,        # é€šå¸¸è®¾ä¸º 2 * lora_rank
    lora_dropout=0.05,
    
    # è®­ç»ƒé…ç½®
    epochs=3,
    batch_size=1,         # CPU å»ºè®®ç”¨ 1
    gradient_accumulation_steps=8,  # ç´¯ç§¯ 8 æ­¥ = æœ‰æ•ˆæ‰¹æ¬¡ 8
    learning_rate=2e-4,
    max_seq_length=512,
    
    # è®¾å¤‡é…ç½®
    device="cpu",         # æˆ– "auto" è‡ªåŠ¨æ£€æµ‹
)

# 2. åˆå§‹åŒ–å¾®è°ƒå™¨
finetuner = LocalLLMFineTuner(config)

# 3. åŠ è½½æ¨¡å‹
finetuner.load_model()

# 4. é…ç½® LoRA
finetuner.setup_lora()

# 5. åŠ è½½è®­ç»ƒæ•°æ®
finetuner.load_data(
    data_path="./data/finetune/train_alpaca.json",
    eval_ratio=0.1,       # 10% ä½œä¸ºéªŒè¯é›†
    data_format="alpaca"  # æ•°æ®æ ¼å¼
)

# 6. å¼€å§‹è®­ç»ƒ
metrics = finetuner.train()

# 7. ä¿å­˜ LoRA é€‚é…å™¨
adapter_path = finetuner.save()

# 8. (å¯é€‰) åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹
merged_path = finetuner.merge_and_save()

# 9. æµ‹è¯•æ•ˆæœ
response = finetuner.chat("è¯·ä»‹ç»ä¸€ä¸‹å°ç±³å…¬å¸çš„å‘å±•å†ç¨‹")
print(response)
```

---

## âš™ï¸ é…ç½®è¯¦è§£

### LocalFineTuneConfig å‚æ•°

```python
@dataclass
class LocalFineTuneConfig:
    # === æ¨¡å‹é…ç½® ===
    base_model: str = "Qwen/Qwen2.5-1.5B-Instruct"
    # HuggingFace æ¨¡å‹ ID æˆ–æœ¬åœ°è·¯å¾„
    # æ¨èæ¨¡å‹:
    #   - Qwen/Qwen2.5-0.5B-Instruct (æœ€å°)
    #   - Qwen/Qwen2.5-1.5B-Instruct (æ¨è)
    #   - Qwen/Qwen2.5-3B-Instruct
    #   - meta-llama/Llama-3.2-1B-Instruct
    #   - mistralai/Mistral-7B-Instruct-v0.3
    
    output_dir: str = "./models/finetuned_llm"
    # å¾®è°ƒè¾“å‡ºç›®å½•
    
    # === LoRA é…ç½® ===
    lora_rank: int = 8
    # LoRA ç§©ï¼Œè¶Šå°å‚æ•°è¶Šå°‘
    # æ¨è: 4(è¶…ä½èµ„æº) / 8(æ¨è) / 16(æ•ˆæœæ›´å¥½)
    
    lora_alpha: int = 16
    # LoRA alphaï¼Œé€šå¸¸è®¾ä¸º 2 * rank
    
    lora_dropout: float = 0.05
    # Dropout æ¯”ä¾‹ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
    
    target_modules: Optional[List[str]] = None
    # è¦å¾®è°ƒçš„æ¨¡å—ï¼ŒNone åˆ™è‡ªåŠ¨æ£€æµ‹
    # Qwen/LLaMA: ["q_proj", "k_proj", "v_proj", "o_proj"]
    
    # === è®­ç»ƒé…ç½® ===
    epochs: int = 3
    # è®­ç»ƒè½®æ•°ï¼Œå°æ•°æ®é›†å»ºè®® 3-5 è½®
    
    batch_size: int = 1
    # æ‰¹æ¬¡å¤§å°ï¼ŒCPU å»ºè®® 1ï¼ŒGPU å¯å¢å¤§
    
    gradient_accumulation_steps: int = 8
    # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    # æœ‰æ•ˆæ‰¹æ¬¡ = batch_size * gradient_accumulation_steps
    
    learning_rate: float = 2e-4
    # å­¦ä¹ ç‡ï¼ŒLoRA é€šå¸¸ç”¨è¾ƒå¤§å­¦ä¹ ç‡
    
    max_seq_length: int = 512
    # æœ€å¤§åºåˆ—é•¿åº¦ï¼Œå½±å“å†…å­˜ä½¿ç”¨
    
    warmup_ratio: float = 0.1
    # å­¦ä¹ ç‡é¢„çƒ­æ¯”ä¾‹
    
    # === è®¾å¤‡é…ç½® ===
    device: str = "auto"
    # è®­ç»ƒè®¾å¤‡: auto / cpu / cuda / mps
    # auto ä¼šè‡ªåŠ¨æ£€æµ‹æœ€ä½³è®¾å¤‡
```

---

## ğŸ“ æ•°æ®æ ¼å¼

### æ”¯æŒçš„æ ¼å¼

#### 1. Alpaca æ ¼å¼ (æ¨è)

```json
[
  {
    "instruction": "é—®é¢˜æˆ–æŒ‡ä»¤",
    "input": "å¯é€‰çš„ä¸Šä¸‹æ–‡",
    "output": "æœŸæœ›çš„å›ç­”"
  }
]
```

#### 2. OpenAI æ ¼å¼

```jsonl
{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]}
```

#### 3. åŸå§‹æ–‡æœ¬æ ¼å¼

```json
[
  {"text": "å®Œæ•´çš„å¯¹è¯æ–‡æœ¬..."}
]
```

### ä½¿ç”¨å·²ç”Ÿæˆçš„æ•°æ®

é¡¹ç›®ä¸­å·²ç»ç”Ÿæˆäº†è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š

```python
# ä½¿ç”¨ Alpaca æ ¼å¼æ•°æ®
finetuner.load_data(
    data_path="./data/finetune/train_alpaca.json",
    data_format="alpaca"
)

# ä½¿ç”¨ OpenAI æ ¼å¼æ•°æ®
finetuner.load_data(
    data_path="./data/finetune/train_openai.jsonl",
    data_format="openai"
)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. å†…å­˜ä¼˜åŒ–

```python
config = LocalFineTuneConfig(
    # ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
    base_model="Qwen/Qwen2.5-0.5B-Instruct",
    
    # å‡å° LoRA ç§©
    lora_rank=4,
    
    # å‡å°åºåˆ—é•¿åº¦
    max_seq_length=256,
    
    # å‡å°æ‰¹æ¬¡ï¼Œå¢åŠ æ¢¯åº¦ç´¯ç§¯
    batch_size=1,
    gradient_accumulation_steps=16,
    
    # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
    gradient_checkpointing=True,
)
```

### 2. æå‡æ•ˆæœ

```python
config = LocalFineTuneConfig(
    # å¢å¤§ LoRA ç§©
    lora_rank=16,
    lora_alpha=32,
    
    # å¢åŠ è®­ç»ƒè½®æ•°
    epochs=5,
    
    # ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆéœ€è¦æ›´å¤šèµ„æºï¼‰
    base_model="Qwen/Qwen2.5-3B-Instruct",
)
```

### 3. æ•°æ®è´¨é‡

- **æ•°æ®é‡**: å»ºè®®è‡³å°‘ 100 æ¡é«˜è´¨é‡æ•°æ®
- **æ•°æ®å¤šæ ·æ€§**: è¦†ç›–ä¸åŒç±»å‹çš„é—®é¢˜
- **ç­”æ¡ˆè´¨é‡**: ç¡®ä¿ç­”æ¡ˆå‡†ç¡®ã€è¯¦ç»†
- **å»é‡**: é¿å…é‡å¤æ•°æ®å¯¼è‡´è¿‡æ‹Ÿåˆ

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶å†…å­˜ä¸è¶³ (OOM)

```python
# è§£å†³æ–¹æ¡ˆ 1: å‡å°æ‰¹æ¬¡
config.batch_size = 1
config.gradient_accumulation_steps = 16

# è§£å†³æ–¹æ¡ˆ 2: å‡å°åºåˆ—é•¿åº¦
config.max_seq_length = 256

# è§£å†³æ–¹æ¡ˆ 3: ä½¿ç”¨æ›´å°çš„æ¨¡å‹
config.base_model = "Qwen/Qwen2.5-0.5B-Instruct"

# è§£å†³æ–¹æ¡ˆ 4: å‡å° LoRA ç§©
config.lora_rank = 4
```

### Q2: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

```python
# CPU è®­ç»ƒæœ¬èº«è¾ƒæ…¢ï¼Œå¯ä»¥:
# 1. å‡å°‘è®­ç»ƒè½®æ•°
config.epochs = 2

# 2. å‡å°‘æ•°æ®é‡ï¼ˆä½¿ç”¨å­é›†ï¼‰
# 3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
# 4. å¦‚æœæœ‰ GPUï¼Œä½¿ç”¨ GPU
config.device = "cuda"
```

### Q3: æ¨¡å‹æ•ˆæœä¸å¥½

```python
# 1. å¢åŠ è®­ç»ƒæ•°æ®
# 2. å¢åŠ è®­ç»ƒè½®æ•°
config.epochs = 5

# 3. è°ƒæ•´å­¦ä¹ ç‡
config.learning_rate = 1e-4  # å°è¯•æ›´å°çš„å­¦ä¹ ç‡

# 4. å¢å¤§ LoRA ç§©
config.lora_rank = 16
```

### Q4: å¦‚ä½•åœ¨å…¶ä»–é¡¹ç›®ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# æ–¹å¼ 1: ä½¿ç”¨ LoRA é€‚é…å™¨
base_model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")
model = PeftModel.from_pretrained(base_model, "./models/finetuned_llm/adapter")

# æ–¹å¼ 2: ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("./models/finetuned_llm/merged")
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¼šè¾“å‡ºä»¥ä¸‹ä¿¡æ¯ï¼š

```
ğŸš€ å¼€å§‹è®­ç»ƒ...
è®­ç»ƒé…ç½®:
   - è½®æ•°: 3
   - æ‰¹æ¬¡å¤§å°: 1
   - æ¢¯åº¦ç´¯ç§¯: 8
   - æœ‰æ•ˆæ‰¹æ¬¡: 8
   - å­¦ä¹ ç‡: 0.0002

{'loss': 2.3456, 'learning_rate': 0.0001, 'epoch': 0.5}
{'loss': 1.8765, 'learning_rate': 0.0002, 'epoch': 1.0}
{'loss': 1.2345, 'learning_rate': 0.00015, 'epoch': 1.5}
...

âœ… è®­ç»ƒå®Œæˆ!
   - æ€»æ­¥æ•°: 150
   - è®­ç»ƒæŸå¤±: 0.8765
   - è®­ç»ƒæ—¶é—´: 1800.5s
```

---

## ğŸ”— ç›¸å…³èµ„æº

- [LoRA è®ºæ–‡](https://arxiv.org/abs/2106.09685)
- [PEFT å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/peft)
- [Qwen2.5 æ¨¡å‹](https://huggingface.co/Qwen)
- [Transformers å¾®è°ƒæŒ‡å—](https://huggingface.co/docs/transformers/training)

---

## ğŸ–¥ï¸ å‘½ä»¤è¡Œå·¥å…·è¯¦è§£

### æ‰€æœ‰å‘½ä»¤ä¸€è§ˆ

| å‘½ä»¤ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `train` | å¾®è°ƒæ¨¡å‹ | `python -m src.stage_4.finetune_main train` |
| `chat` | äº¤äº’å¼å¯¹è¯ | `python -m src.stage_4.finetune_main chat` |
| `test` | æµ‹è¯•æ¨¡å‹æ•ˆæœ | `python -m src.stage_4.finetune_main test` |
| `compare` | å¯¹æ¯”å¾®è°ƒå‰å | `python -m src.stage_4.finetune_main compare` |
| `generate` | ç”Ÿæˆè®­ç»ƒæ•°æ® | `python -m src.stage_4.finetune_main generate` |

### train å‘½ä»¤å‚æ•°

```bash
python -m src.stage_4.finetune_main train [OPTIONS]

Options:
  -d, --data PATH          è®­ç»ƒæ•°æ®è·¯å¾„ (é»˜è®¤: ./data/finetune/train_alpaca.json)
  -m, --model MODEL        åŸºç¡€æ¨¡å‹ (é»˜è®¤: Qwen/Qwen2.5-0.5B-Instruct)
  -o, --output PATH        è¾“å‡ºç›®å½• (é»˜è®¤: ./models/finetuned_llm)
  -e, --epochs INT         è®­ç»ƒè½®æ•° (é»˜è®¤: 3)
  -r, --lora-rank INT      LoRA rank (é»˜è®¤: 8)
  -b, --batch-size INT     æ‰¹æ¬¡å¤§å° (é»˜è®¤: 1)
  --max-seq-length INT     æœ€å¤§åºåˆ—é•¿åº¦ (é»˜è®¤: 512)
  -lr, --learning-rate     å­¦ä¹ ç‡ (é»˜è®¤: 2e-4)
  --device DEVICE          è®­ç»ƒè®¾å¤‡: auto/cpu/cuda/mps (é»˜è®¤: auto)
```

### chat å‘½ä»¤å‚æ•°

```bash
python -m src.stage_4.finetune_main chat [OPTIONS]

Options:
  -p, --model-path PATH    æ¨¡å‹é€‚é…å™¨è·¯å¾„ (é»˜è®¤: ./models/finetuned_llm/adapter)
  -m, --base-model MODEL   åŸºç¡€æ¨¡å‹ (é»˜è®¤: Qwen/Qwen2.5-0.5B-Instruct)
  --device DEVICE          æ¨ç†è®¾å¤‡ (é»˜è®¤: auto)
```

### å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

```bash
# Step 1: æ£€æŸ¥ç¯å¢ƒ
python scripts/test_local_finetune.py

# Step 2: (å¯é€‰) é‡æ–°ç”Ÿæˆè®­ç»ƒæ•°æ®
python -m src.stage_4.finetune_main generate --data-dir ./data/documents

# Step 3: å¼€å§‹å¾®è°ƒ
python -m src.stage_4.finetune_main train --model Qwen/Qwen2.5-0.5B-Instruct --epochs 3

# Step 4: æµ‹è¯•æ¨¡å‹æ•ˆæœ
python -m src.stage_4.finetune_main test

# Step 5: äº¤äº’å¼å¯¹è¯
python -m src.stage_4.finetune_main chat

# Step 6: (å¯é€‰) å¯¹æ¯”å¾®è°ƒå‰åæ•ˆæœ
python -m src.stage_4.finetune_main compare
```

---

## ğŸ“ å®Œæ•´ç¤ºä¾‹

### å‘½ä»¤è¡Œæ–¹å¼ (æ¨è)

```bash
# å®Œæ•´çš„å¾®è°ƒæµç¨‹
python -m src.stage_4.finetune_main train \
    --model Qwen/Qwen2.5-0.5B-Instruct \
    --data ./data/finetune/train_alpaca.json \
    --output ./models/my_finetuned_model \
    --epochs 3 \
    --lora-rank 8

# ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹å¯¹è¯
python -m src.stage_4.finetune_main chat \
    --model-path ./models/my_finetuned_model/adapter \
    --base-model Qwen/Qwen2.5-0.5B-Instruct
```

### Python API æ–¹å¼

```python
"""
å®Œæ•´çš„æœ¬åœ°å¾®è°ƒç¤ºä¾‹
"""
from src.stage_4.fine_tuning import (
    LocalLLMFineTuner,
    LocalFineTuneConfig,
    quick_finetune,
)

# ============== æ–¹å¼ 1: å¿«é€Ÿå¾®è°ƒ ==============
result = quick_finetune(
    data_path="./data/finetune/train_alpaca.json",
    model="Qwen/Qwen2.5-0.5B-Instruct",
    output_dir="./models/my_model",
    epochs=3,
)

# ============== æ–¹å¼ 2: è‡ªå®šä¹‰é…ç½® ==============
config = LocalFineTuneConfig(
    base_model="Qwen/Qwen2.5-1.5B-Instruct",
    output_dir="./models/custom_model",
    lora_rank=8,
    epochs=3,
    device="cpu",
)

finetuner = LocalLLMFineTuner(config)
finetuner.run_full_pipeline("./data/finetune/train_alpaca.json")

# ============== æ–¹å¼ 3: åˆ†æ­¥æ‰§è¡Œ ==============
finetuner = LocalLLMFineTuner()
finetuner.load_model()
finetuner.setup_lora()
finetuner.load_data("./data/finetune/train_alpaca.json")
finetuner.train()
finetuner.save()

# æµ‹è¯•
response = finetuner.chat("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
print(response)
```

---

## ğŸ¬ å¿«é€Ÿæ¼”ç¤º

### 30 ç§’å¿«é€Ÿä½“éªŒ

```bash
# 1. å®‰è£…ä¾èµ– (é¦–æ¬¡)
pip install -r requirements.txt

# 2. ä¸€é”®å¾®è°ƒ
python -m src.stage_4.finetune_main train --epochs 1

# 3. å¼€å§‹å¯¹è¯
python -m src.stage_4.finetune_main chat
```

### äº¤äº’å¼å¯¹è¯ç¤ºä¾‹

```
============================================================
ğŸ’¬ å¾®è°ƒæ¨¡å‹å¯¹è¯
============================================================

ğŸ“‚ åŠ è½½æ¨¡å‹é€‚é…å™¨: ./models/finetuned_llm/adapter
ğŸ“¦ åŸºç¡€æ¨¡å‹: Qwen/Qwen2.5-0.5B-Instruct

âœ… æ¨¡å‹åŠ è½½å®Œæˆ!
   - è®¾å¤‡: mps

------------------------------------------------------------
å¼€å§‹å¯¹è¯ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼Œ'clear' æ¸…å±ï¼‰
------------------------------------------------------------

ğŸ§‘ ä½ : å°ç±³å…¬å¸æ˜¯ä»€ä¹ˆæ—¶å€™æˆç«‹çš„ï¼Ÿ

ğŸ¤– åŠ©æ‰‹: æ ¹æ®æ–‡æ¡£å†…å®¹ï¼Œå°ç±³ç§‘æŠ€æœ‰é™è´£ä»»å…¬å¸æˆç«‹äº2010å¹´3æœˆ3æ—¥ï¼Œ
æ€»éƒ¨ä½äºåŒ—äº¬å¸‚æµ·æ·€åŒºå®‰å®åº„è·¯å°ç±³ç§‘æŠ€å›­ï¼Œå…¬å¸çš„åˆ›å§‹äººæ˜¯é›·å†›ã€‚

ğŸ§‘ ä½ : å°ç±³çš„ä¸»è¦ä¸šåŠ¡æœ‰å“ªäº›ï¼Ÿ

ğŸ¤– åŠ©æ‰‹: å°ç±³ä¸»è¦ä»äº‹æ™ºèƒ½æ‰‹æœºã€æ™ºèƒ½æ±½è½¦ã€èŠ¯ç‰‡ã€ç‰©è”ç½‘ï¼ˆIoTï¼‰ä»¥åŠ
ç”Ÿæ´»æ¶ˆè´¹äº§å“çš„ç ”å‘å’Œé”€å”®ã€‚æ­¤å¤–ï¼Œå…¬å¸è¿˜æä¾›äº’è”ç½‘æœåŠ¡ï¼Œå¹¶ä»äº‹æŠ•èµ„ä¸šåŠ¡ã€‚

ğŸ§‘ ä½ : quit

ğŸ‘‹ å†è§ï¼
```

