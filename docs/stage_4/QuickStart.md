# Stage 4 å¿«é€Ÿå…¥é—¨æŒ‡å—

> 5 åˆ†é’Ÿä¸Šæ‰‹ GraphRAG & Fine-tuning

---

## ğŸš€ ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£…ä¾èµ–

```bash
cd /path/to/UltimateRAG
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# API é…ç½® (äºŒé€‰ä¸€)
OPENAI_API_KEY=your_openai_api_key
# æˆ–ä½¿ç”¨é˜¿é‡Œäº‘
DASHSCOPE_API_KEY=your_dashscope_api_key
OPENAI_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# æ¨¡å‹é…ç½®
MODEL_NAME=qwen-plus
EMBEDDING_MODEL=text-embedding-v3

# å›¾å­˜å‚¨ (å¯é€‰ï¼Œé»˜è®¤ memory)
GRAPH_STORE_TYPE=memory
```

### 3. å‡†å¤‡æ•°æ®

å°†æ–‡æ¡£æ”¾å…¥ `data/documents/` ç›®å½•ï¼Œæ”¯æŒæ ¼å¼ï¼š
- PDF (`.pdf`)
- Markdown (`.md`)
- Word (`.docx`)
- æ–‡æœ¬ (`.txt`)

---

## ğŸ“Š GraphRAG å¿«é€Ÿä½“éªŒ

### æ–¹å¼ä¸€ï¼šäº¤äº’å¼æ¼”ç¤º

```bash
python -m src.stage_4.main
```

é€‰æ‹© `1` è¿›å…¥ GraphRAG æ¼”ç¤ºæ¨¡å¼ã€‚

### æ–¹å¼äºŒï¼šä»£ç è°ƒç”¨

```python
from src.stage_1.document_loader import DocumentLoader
from src.stage_1.chunker import TextChunker
from src.stage_4.graph_rag import GraphRAGChain

# 1. åŠ è½½æ–‡æ¡£
loader = DocumentLoader()
documents = loader.load_directory("./data/documents")

# 2. åˆ†å—
chunker = TextChunker()
chunks = chunker.split_documents(documents)

# 3. åˆå§‹åŒ– GraphRAG
graph_rag = GraphRAGChain(
    documents=chunks,
    graph_name="my_knowledge_graph",
    force_rebuild=True,  # é¦–æ¬¡è¿è¡Œè®¾ä¸º True
)

# 4. æ„å»ºçŸ¥è¯†å›¾è°±
graph_rag.build_knowledge_graph(chunks)

# 5. æŸ¥çœ‹å›¾è°±ç»Ÿè®¡
stats = graph_rag.get_statistics()
print(f"å®ä½“æ•°: {stats['num_nodes']}, å…³ç³»æ•°: {stats['num_edges']}")

# 6. æé—®
result = graph_rag.ask("æ–‡æ¡£ä¸­æåˆ°çš„ä¸»è¦äººç‰©æœ‰å“ªäº›ï¼Ÿä»–ä»¬ä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ")
print(result.answer)
```

---

## ğŸ¯ ç»ˆæ RAG å¿«é€Ÿä½“éªŒ

æ•´åˆ Stage 1-4 æ‰€æœ‰èƒ½åŠ›çš„æœ€å¼º RAGï¼š

```python
from src.stage_4.ultimate_rag_chain import UltimateRAGChain, RetrievalMode

# åˆå§‹åŒ–ï¼ˆè‡ªåŠ¨æ•´åˆå‘é‡æ£€ç´¢ + å›¾æ£€ç´¢ + è‡ªåæ€ï¼‰
ultimate_rag = UltimateRAGChain(
    documents=chunks,
    enable_routing=True,      # æ™ºèƒ½è·¯ç”±
    enable_self_rag=True,     # è‡ªåæ€
    enable_graph_rag=True,    # å›¾æ£€ç´¢
    enable_reranking=True,    # é‡æ’åº
)

# è‡ªåŠ¨æ¨¡å¼ï¼ˆç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥ï¼‰
result = ultimate_rag.ask("é—®é¢˜å†…å®¹")

# æŒ‡å®šæ£€ç´¢æ¨¡å¼
result = ultimate_rag.ask("å…³ç³»ç±»é—®é¢˜", retrieval_mode=RetrievalMode.GRAPH)
result = ultimate_rag.ask("ä¸€èˆ¬é—®é¢˜", retrieval_mode=RetrievalMode.VECTOR)
result = ultimate_rag.ask("å¤æ‚é—®é¢˜", retrieval_mode=RetrievalMode.FUSION)
```

**æ£€ç´¢æ¨¡å¼è¯´æ˜ï¼š**

| æ¨¡å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| `AUTO` | è‡ªåŠ¨é€‰æ‹© | ä¸ç¡®å®šé—®é¢˜ç±»å‹æ—¶ |
| `VECTOR` | çº¯å‘é‡æ£€ç´¢ | ä¸€èˆ¬è¯­ä¹‰ç›¸ä¼¼é—®é¢˜ |
| `HYBRID` | æ··åˆæ£€ç´¢ | åŒ…å«ä¸“æœ‰åè¯çš„é—®é¢˜ |
| `GRAPH` | çº¯å›¾æ£€ç´¢ | å…³ç³»æŸ¥è¯¢ã€è·¯å¾„æŸ¥è¯¢ |
| `FUSION` | èåˆæ£€ç´¢ | å¤æ‚çš„ç»¼åˆæ€§é—®é¢˜ |

---

## ğŸ“š å¾®è°ƒæ•°æ®ç”Ÿæˆ

### ç”Ÿæˆ LLM å¾®è°ƒæ•°æ®

```python
from src.stage_4.fine_tuning import LLMFineTuner

# åˆå§‹åŒ–
finetuner = LLMFineTuner()

# ç”Ÿæˆ QA å¯¹
qa_pairs = finetuner.generate_qa_pairs(
    documents=chunks,
    pairs_per_doc=5,  # æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆ 5 ä¸ª QA
)

# å¯¼å‡ºä¸ºä¸åŒæ ¼å¼
finetuner.export_jsonl()                    # OpenAI æ ¼å¼ (JSONL)
finetuner.export_json()                     # Alpaca æ ¼å¼ (JSON)

# æŸ¥çœ‹ç»Ÿè®¡
print(finetuner.get_statistics())
```

**è¾“å‡ºæ–‡ä»¶ä½ç½®ï¼š** `./data/finetune/`

### ç”Ÿæˆ Embedding è®­ç»ƒæ•°æ®

```python
from src.stage_4.fine_tuning import EmbeddingFineTuner

# åˆå§‹åŒ–
emb_finetuner = EmbeddingFineTuner(
    base_model="BAAI/bge-base-zh-v1.5",
    output_dir="./models/my_embedding",
)

# ç”Ÿæˆè®­ç»ƒæ•°æ®
pairs, triplets = emb_finetuner.generate_training_data(chunks)

# ä¿å­˜
emb_finetuner.save_training_data()

# å¼€å§‹å¾®è°ƒï¼ˆéœ€è¦ GPUï¼‰
# emb_finetuner.train(epochs=3)
```

---

## ğŸ” å¸¸ç”¨æ“ä½œé€ŸæŸ¥

### æŸ¥è¯¢å®ä½“ä¿¡æ¯

```python
info = graph_rag.get_entity_info("åä¸º")
print(f"å®ä½“: {info['entity']['name']}")
print(f"é‚»å±…: {[n['name'] for n in info['neighbors']]}")
print(f"å…³ç³»: {len(info['relations'])} æ¡")
```

### æŸ¥æ‰¾å®ä½“é—´è·¯å¾„

```python
path = graph_rag.find_path("ä»»æ­£é", "æ·±åœ³")
if path:
    for step in path:
        entity = step['entity']['name']
        relation = step['relation']['relation_type'] if step['relation'] else 'èµ·ç‚¹'
        print(f"  {entity} [{relation}]")
```

### ç”Ÿæˆå…¨å±€æ‘˜è¦

```python
summary = graph_rag.generate_global_summary()
print(summary)
```

### è·å–å›¾è°±ç»Ÿè®¡

```python
stats = graph_rag.get_statistics()
print(f"å®ä½“ç±»å‹åˆ†å¸ƒ: {stats['entity_type_counts']}")
print(f"å…³ç³»ç±»å‹åˆ†å¸ƒ: {stats['relation_type_counts']}")
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### Q: å›¾è°±æ„å»ºå¤ªæ…¢ï¼Ÿ

A: å›¾è°±æ„å»ºéœ€è¦è°ƒç”¨ LLM è¿›è¡Œå®ä½“/å…³ç³»æŠ½å–ï¼Œå¯ä»¥ï¼š
- å‡å°‘æ–‡æ¡£æ•°é‡è¿›è¡Œæµ‹è¯•
- ä½¿ç”¨æ›´å¿«çš„ LLMï¼ˆå¦‚ qwen-turboï¼‰
- è®¾ç½® `force_rebuild=False` å¤ç”¨å·²æœ‰å›¾è°±

### Q: å¦‚ä½•ä½¿ç”¨ Neo4jï¼Ÿ

A: åœ¨ `.env` ä¸­é…ç½®ï¼š

```env
GRAPH_STORE_TYPE=neo4j
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
```

ç„¶åå®‰è£… Neo4j Desktop æˆ–ä½¿ç”¨ Docker å¯åŠ¨ Neo4jã€‚

### Q: å¾®è°ƒéœ€è¦ä»€ä¹ˆç¡¬ä»¶ï¼Ÿ

A: 
- Embedding å¾®è°ƒï¼šæ¨è 8GB+ æ˜¾å­˜çš„ GPU
- ä»…ç”Ÿæˆæ•°æ®ï¼šCPU å³å¯

### Q: å¦‚ä½•è¯„ä¼°æ•ˆæœï¼Ÿ

A: å‚è€ƒ Stage 5 çš„è¯„ä¼°æ¡†æ¶ï¼Œæˆ–æ‰‹åŠ¨è¯„ä¼°ï¼š
- æ£€æŸ¥æŠ½å–çš„å®ä½“æ˜¯å¦å‡†ç¡®
- æ£€æŸ¥å…³ç³»æ˜¯å¦æœ‰æ„ä¹‰
- å¯¹æ¯”æœ‰æ— å›¾æ£€ç´¢çš„ç­”æ¡ˆè´¨é‡

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶è¯´æ˜

| æ–‡ä»¶/ç›®å½• | è¯´æ˜ |
|----------|------|
| `./data/graph_db/*.json` | çŸ¥è¯†å›¾è°±æŒä¹…åŒ–æ–‡ä»¶ |
| `./data/finetune/train_openai.jsonl` | OpenAI æ ¼å¼å¾®è°ƒæ•°æ® |
| `./data/finetune/train_alpaca.json` | Alpaca æ ¼å¼å¾®è°ƒæ•°æ® |
| `./data/finetune/qa_pairs.json` | åŸå§‹ QA å¯¹ |
| `./models/finetuned_embedding/` | å¾®è°ƒåçš„ Embedding æ¨¡å‹ |

---

## ğŸ‰ ä¸‹ä¸€æ­¥

- é˜…è¯» [å®Œæ•´æ–‡æ¡£](./README.md) äº†è§£æ›´å¤šåŠŸèƒ½
- æŸ¥çœ‹ [å¼€å‘è®¡åˆ’](./plan.md) äº†è§£å®ç°ç»†èŠ‚
- æ¢ç´¢ Stage 5 çš„è¯„ä¼°å’Œç›‘æ§åŠŸèƒ½

Happy Coding! ğŸš€

